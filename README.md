# AI Use Case Classifer: EU AI ACT

This Java project is directly inspired by the EU AI Act's risk-based framework, which categorizes AI systems into different risk levels:
- Prohibited AI Systems: Systems that pose unacceptable risks
- High-Risk AI Systems: Systems that require strict compliance measures
- Limited Risk AI Systems: Systems with specific transparency requirements
- Minimal Risk AI Systems: Systems with minimal regulatory obligations

**Key Features:**

Risk Classification Engine
- Evaluates AI systems against the EU AI Act's specific criteria
- Uses a questionnaire-based approach to determine risk category
- Identifies prohibited practices that aren't allowed under the EU AI Act

Compliance Recommendation Generator
- Provides tailored governance recommendations based on risk category
- Suggests specific measures required by the EU AI Act
- Offers practical implementation guidance

Simple User Interface
- Clear explanations of risk categories
- Structured display of compliance requirements

**How it works:**

The application walks users through a series of questions about their AI system, covering:
- Basic system information
- Potential prohibited use cases (manipulative techniques, exploitation of vulnerabilities)
- High-risk domain assessment (education, employment, law enforcement, etc.)
- Transparency requirements (human interaction, deepfakes, emotion recognition)

Based on responses, it determines the appropriate risk category and provides specific compliance recommendations aligned with the EU AI Act's requirements.
